# HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles.
# TYPE go_gc_duration_seconds summary
go_gc_duration_seconds{quantile="0"} 2.5291e-05
go_gc_duration_seconds{quantile="0.25"} 5.4192e-05
go_gc_duration_seconds{quantile="0.5"} 5.7117e-05
go_gc_duration_seconds{quantile="0.75"} 6.5804e-05
go_gc_duration_seconds{quantile="1"} 0.000725681
go_gc_duration_seconds_sum 0.009227788
go_gc_duration_seconds_count 131
# HELP go_goroutines Number of goroutines that currently exist.
# TYPE go_goroutines gauge
go_goroutines 65
# HELP go_info Information about the Go environment.
# TYPE go_info gauge
go_info{version="go1.20.8"} 1
# HELP go_memstats_alloc_bytes Number of bytes allocated and still in use.
# TYPE go_memstats_alloc_bytes gauge
go_memstats_alloc_bytes 4.1914064e+07
# HELP go_memstats_alloc_bytes_total Total number of bytes allocated, even if freed.
# TYPE go_memstats_alloc_bytes_total counter
go_memstats_alloc_bytes_total 1.880054952e+09
# HELP go_memstats_buck_hash_sys_bytes Number of bytes used by the profiling bucket hash table.
# TYPE go_memstats_buck_hash_sys_bytes gauge
go_memstats_buck_hash_sys_bytes 1.651604e+06
# HELP go_memstats_frees_total Total number of frees.
# TYPE go_memstats_frees_total counter
go_memstats_frees_total 1.0213548e+07
# HELP go_memstats_gc_sys_bytes Number of bytes used for garbage collection system metadata.
# TYPE go_memstats_gc_sys_bytes gauge
go_memstats_gc_sys_bytes 1.0649344e+07
# HELP go_memstats_heap_alloc_bytes Number of heap bytes allocated and still in use.
# TYPE go_memstats_heap_alloc_bytes gauge
go_memstats_heap_alloc_bytes 4.1914064e+07
# HELP go_memstats_heap_idle_bytes Number of heap bytes waiting to be used.
# TYPE go_memstats_heap_idle_bytes gauge
go_memstats_heap_idle_bytes 6.6166784e+07
# HELP go_memstats_heap_inuse_bytes Number of heap bytes that are in use.
# TYPE go_memstats_heap_inuse_bytes gauge
go_memstats_heap_inuse_bytes 4.8553984e+07
# HELP go_memstats_heap_objects Number of allocated objects.
# TYPE go_memstats_heap_objects gauge
go_memstats_heap_objects 205819
# HELP go_memstats_heap_released_bytes Number of heap bytes released to OS.
# TYPE go_memstats_heap_released_bytes gauge
go_memstats_heap_released_bytes 6.0596224e+07
# HELP go_memstats_heap_sys_bytes Number of heap bytes obtained from system.
# TYPE go_memstats_heap_sys_bytes gauge
go_memstats_heap_sys_bytes 1.14720768e+08
# HELP go_memstats_last_gc_time_seconds Number of seconds since 1970 of last garbage collection.
# TYPE go_memstats_last_gc_time_seconds gauge
go_memstats_last_gc_time_seconds 1.727949594564178e+09
# HELP go_memstats_lookups_total Total number of pointer lookups.
# TYPE go_memstats_lookups_total counter
go_memstats_lookups_total 0
# HELP go_memstats_mallocs_total Total number of mallocs.
# TYPE go_memstats_mallocs_total counter
go_memstats_mallocs_total 1.0419367e+07
# HELP go_memstats_mcache_inuse_bytes Number of bytes in use by mcache structures.
# TYPE go_memstats_mcache_inuse_bytes gauge
go_memstats_mcache_inuse_bytes 9600
# HELP go_memstats_mcache_sys_bytes Number of bytes used for mcache structures obtained from system.
# TYPE go_memstats_mcache_sys_bytes gauge
go_memstats_mcache_sys_bytes 15600
# HELP go_memstats_mspan_inuse_bytes Number of bytes in use by mspan structures.
# TYPE go_memstats_mspan_inuse_bytes gauge
go_memstats_mspan_inuse_bytes 580160
# HELP go_memstats_mspan_sys_bytes Number of bytes used for mspan structures obtained from system.
# TYPE go_memstats_mspan_sys_bytes gauge
go_memstats_mspan_sys_bytes 848640
# HELP go_memstats_next_gc_bytes Number of heap bytes when next garbage collection will take place.
# TYPE go_memstats_next_gc_bytes gauge
go_memstats_next_gc_bytes 6.5760128e+07
# HELP go_memstats_other_sys_bytes Number of bytes used for other system allocations.
# TYPE go_memstats_other_sys_bytes gauge
go_memstats_other_sys_bytes 1.662612e+06
# HELP go_memstats_stack_inuse_bytes Number of bytes in use by the stack allocator.
# TYPE go_memstats_stack_inuse_bytes gauge
go_memstats_stack_inuse_bytes 2.719744e+06
# HELP go_memstats_stack_sys_bytes Number of bytes obtained from system for stack allocator.
# TYPE go_memstats_stack_sys_bytes gauge
go_memstats_stack_sys_bytes 2.719744e+06
# HELP go_memstats_sys_bytes Number of bytes obtained from system.
# TYPE go_memstats_sys_bytes gauge
go_memstats_sys_bytes 1.32268312e+08
# HELP go_threads Number of OS threads created.
# TYPE go_threads gauge
go_threads 14
# HELP net_conntrack_dialer_conn_attempted_total Total number of connections attempted by the given dialer a given name.
# TYPE net_conntrack_dialer_conn_attempted_total counter
net_conntrack_dialer_conn_attempted_total{dialer_name="alertmanager"} 1
net_conntrack_dialer_conn_attempted_total{dialer_name="default"} 0
net_conntrack_dialer_conn_attempted_total{dialer_name="prometheus"} 5
net_conntrack_dialer_conn_attempted_total{dialer_name="remote_storage_write_client"} 6
# HELP net_conntrack_dialer_conn_closed_total Total number of connections closed which originated from the dialer of a given name.
# TYPE net_conntrack_dialer_conn_closed_total counter
net_conntrack_dialer_conn_closed_total{dialer_name="alertmanager"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="default"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="prometheus"} 1
net_conntrack_dialer_conn_closed_total{dialer_name="remote_storage_write_client"} 4
# HELP net_conntrack_dialer_conn_established_total Total number of connections successfully established by the given dialer a given name.
# TYPE net_conntrack_dialer_conn_established_total counter
net_conntrack_dialer_conn_established_total{dialer_name="alertmanager"} 1
net_conntrack_dialer_conn_established_total{dialer_name="default"} 0
net_conntrack_dialer_conn_established_total{dialer_name="prometheus"} 4
net_conntrack_dialer_conn_established_total{dialer_name="remote_storage_write_client"} 6
# HELP net_conntrack_dialer_conn_failed_total Total number of connections failed to dial by the dialer a given name.
# TYPE net_conntrack_dialer_conn_failed_total counter
net_conntrack_dialer_conn_failed_total{dialer_name="alertmanager",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="alertmanager",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="alertmanager",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="alertmanager",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="default",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="default",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="default",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="default",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="prometheus",reason="refused"} 1
net_conntrack_dialer_conn_failed_total{dialer_name="prometheus",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="prometheus",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="prometheus",reason="unknown"} 1
net_conntrack_dialer_conn_failed_total{dialer_name="remote_storage_write_client",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="remote_storage_write_client",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="remote_storage_write_client",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="remote_storage_write_client",reason="unknown"} 0
# HELP net_conntrack_listener_conn_accepted_total Total number of connections opened to the listener of a given name.
# TYPE net_conntrack_listener_conn_accepted_total counter
net_conntrack_listener_conn_accepted_total{listener_name="http"} 6
# HELP net_conntrack_listener_conn_closed_total Total number of connections closed that were made to the listener of a given name.
# TYPE net_conntrack_listener_conn_closed_total counter
net_conntrack_listener_conn_closed_total{listener_name="http"} 4
# HELP process_cpu_seconds_total Total user and system CPU time spent in seconds.
# TYPE process_cpu_seconds_total counter
process_cpu_seconds_total 25.22
# HELP process_max_fds Maximum number of open file descriptors.
# TYPE process_max_fds gauge
process_max_fds 4096
# HELP process_open_fds Number of open file descriptors.
# TYPE process_open_fds gauge
process_open_fds 40
# HELP process_resident_memory_bytes Resident memory size in bytes.
# TYPE process_resident_memory_bytes gauge
process_resident_memory_bytes 1.09101056e+08
# HELP process_start_time_seconds Start time of the process since unix epoch in seconds.
# TYPE process_start_time_seconds gauge
process_start_time_seconds 1.72793594073e+09
# HELP process_virtual_memory_bytes Virtual memory size in bytes.
# TYPE process_virtual_memory_bytes gauge
process_virtual_memory_bytes 1.49792768e+09
# HELP process_virtual_memory_max_bytes Maximum amount of virtual memory available in bytes.
# TYPE process_virtual_memory_max_bytes gauge
process_virtual_memory_max_bytes 1.8446744073709552e+19
# HELP prometheus_api_remote_read_queries The current number of remote read queries being executed or waiting.
# TYPE prometheus_api_remote_read_queries gauge
prometheus_api_remote_read_queries 0
# HELP prometheus_build_info A metric with a constant '1' value labeled by version, revision, branch, goversion from which prometheus was built, and the goos and goarch forthe build.
# TYPE prometheus_build_info gauge
prometheus_build_info{branch="HEAD",goarch="amd64",goos="linux",goversion="go1.20.8",revision="c62de5d1075d9c24a281b4b719f124f14e730fa5",tags="netgo,builtinassets,stringlabels",version="2.45.1"} 1
# HELP prometheus_config_last_reload_success_timestamp_seconds Timestamp of the last successful configuration reload.
# TYPE prometheus_config_last_reload_success_timestamp_seconds gauge
prometheus_config_last_reload_success_timestamp_seconds 1.7279359423040752e+09
# HELP prometheus_config_last_reload_successful Whether the last configuration reload attempt was successful.
# TYPE prometheus_config_last_reload_successful gauge
prometheus_config_last_reload_successful 1
# HELP prometheus_engine_queries The current number of queries being executed or waiting.
# TYPE prometheus_engine_queries gauge
prometheus_engine_queries 0
# HELP prometheus_engine_queries_concurrent_max The max number of concurrent queries.
# TYPE prometheus_engine_queries_concurrent_max gauge
prometheus_engine_queries_concurrent_max 20
# HELP prometheus_engine_query_duration_seconds Query timings
# TYPE prometheus_engine_query_duration_seconds summary
prometheus_engine_query_duration_seconds{slice="inner_eval",quantile="0.5"} 3.2644e-05
prometheus_engine_query_duration_seconds{slice="inner_eval",quantile="0.9"} 7.6412e-05
prometheus_engine_query_duration_seconds{slice="inner_eval",quantile="0.99"} 0.000108933
prometheus_engine_query_duration_seconds_sum{slice="inner_eval"} 0.11750786800000021
prometheus_engine_query_duration_seconds_count{slice="inner_eval"} 2988
prometheus_engine_query_duration_seconds{slice="prepare_time",quantile="0.5"} 4.0346e-05
prometheus_engine_query_duration_seconds{slice="prepare_time",quantile="0.9"} 6.4782e-05
prometheus_engine_query_duration_seconds{slice="prepare_time",quantile="0.99"} 0.000141162
prometheus_engine_query_duration_seconds_sum{slice="prepare_time"} 0.12909381400000008
prometheus_engine_query_duration_seconds_count{slice="prepare_time"} 2988
prometheus_engine_query_duration_seconds{slice="queue_time",quantile="0.5"} 6.472e-06
prometheus_engine_query_duration_seconds{slice="queue_time",quantile="0.9"} 2.3998e-05
prometheus_engine_query_duration_seconds{slice="queue_time",quantile="0.99"} 3.2861e-05
prometheus_engine_query_duration_seconds_sum{slice="queue_time"} 0.02950833099999999
prometheus_engine_query_duration_seconds_count{slice="queue_time"} 2988
prometheus_engine_query_duration_seconds{slice="result_sort",quantile="0.5"} NaN
prometheus_engine_query_duration_seconds{slice="result_sort",quantile="0.9"} NaN
prometheus_engine_query_duration_seconds{slice="result_sort",quantile="0.99"} NaN
prometheus_engine_query_duration_seconds_sum{slice="result_sort"} 0
prometheus_engine_query_duration_seconds_count{slice="result_sort"} 0
# HELP prometheus_engine_query_log_enabled State of the query log.
# TYPE prometheus_engine_query_log_enabled gauge
prometheus_engine_query_log_enabled 0
# HELP prometheus_engine_query_log_failures_total The number of query log failures.
# TYPE prometheus_engine_query_log_failures_total counter
prometheus_engine_query_log_failures_total 0
# HELP prometheus_engine_query_samples_total The total number of samples loaded by all queries.
# TYPE prometheus_engine_query_samples_total counter
prometheus_engine_query_samples_total 14504
# HELP prometheus_http_request_duration_seconds Histogram of latencies for HTTP requests.
# TYPE prometheus_http_request_duration_seconds histogram
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/admin/tsdb/snapshot",le="0.1"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/admin/tsdb/snapshot",le="0.2"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/admin/tsdb/snapshot",le="0.4"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/admin/tsdb/snapshot",le="1"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/admin/tsdb/snapshot",le="3"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/admin/tsdb/snapshot",le="8"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/admin/tsdb/snapshot",le="20"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/admin/tsdb/snapshot",le="60"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/admin/tsdb/snapshot",le="120"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/admin/tsdb/snapshot",le="+Inf"} 2
prometheus_http_request_duration_seconds_sum{handler="/api/v1/admin/tsdb/snapshot"} 0.154146833
prometheus_http_request_duration_seconds_count{handler="/api/v1/admin/tsdb/snapshot"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/targets",le="0.1"} 1
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/targets",le="0.2"} 1
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/targets",le="0.4"} 1
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/targets",le="1"} 1
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/targets",le="3"} 1
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/targets",le="8"} 1
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/targets",le="20"} 1
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/targets",le="60"} 1
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/targets",le="120"} 1
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/targets",le="+Inf"} 1
prometheus_http_request_duration_seconds_sum{handler="/api/v1/targets"} 0.000345504
prometheus_http_request_duration_seconds_count{handler="/api/v1/targets"} 1
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="0.1"} 229
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="0.2"} 229
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="0.4"} 229
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="1"} 229
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="3"} 229
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="8"} 229
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="20"} 229
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="60"} 229
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="120"} 229
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="+Inf"} 229
prometheus_http_request_duration_seconds_sum{handler="/metrics"} 0.6187749620000002
prometheus_http_request_duration_seconds_count{handler="/metrics"} 229
# HELP prometheus_http_requests_total Counter of HTTP requests.
# TYPE prometheus_http_requests_total counter
prometheus_http_requests_total{code="200",handler="/api/v1/admin/tsdb/snapshot"} 2
prometheus_http_requests_total{code="200",handler="/api/v1/targets"} 1
prometheus_http_requests_total{code="200",handler="/metrics"} 229
# HELP prometheus_http_response_size_bytes Histogram of response size for HTTP requests.
# TYPE prometheus_http_response_size_bytes histogram
prometheus_http_response_size_bytes_bucket{handler="/api/v1/admin/tsdb/snapshot",le="100"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/admin/tsdb/snapshot",le="1000"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/admin/tsdb/snapshot",le="10000"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/admin/tsdb/snapshot",le="100000"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/admin/tsdb/snapshot",le="1e+06"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/admin/tsdb/snapshot",le="1e+07"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/admin/tsdb/snapshot",le="1e+08"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/admin/tsdb/snapshot",le="1e+09"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/admin/tsdb/snapshot",le="+Inf"} 2
prometheus_http_response_size_bytes_sum{handler="/api/v1/admin/tsdb/snapshot"} 144
prometheus_http_response_size_bytes_count{handler="/api/v1/admin/tsdb/snapshot"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/targets",le="100"} 0
prometheus_http_response_size_bytes_bucket{handler="/api/v1/targets",le="1000"} 0
prometheus_http_response_size_bytes_bucket{handler="/api/v1/targets",le="10000"} 1
prometheus_http_response_size_bytes_bucket{handler="/api/v1/targets",le="100000"} 1
prometheus_http_response_size_bytes_bucket{handler="/api/v1/targets",le="1e+06"} 1
prometheus_http_response_size_bytes_bucket{handler="/api/v1/targets",le="1e+07"} 1
prometheus_http_response_size_bytes_bucket{handler="/api/v1/targets",le="1e+08"} 1
prometheus_http_response_size_bytes_bucket{handler="/api/v1/targets",le="1e+09"} 1
prometheus_http_response_size_bytes_bucket{handler="/api/v1/targets",le="+Inf"} 1
prometheus_http_response_size_bytes_sum{handler="/api/v1/targets"} 1812
prometheus_http_response_size_bytes_count{handler="/api/v1/targets"} 1
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="100"} 0
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="1000"} 0
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="10000"} 0
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="100000"} 229
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="1e+06"} 229
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="1e+07"} 229
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="1e+08"} 229
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="1e+09"} 229
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="+Inf"} 229
prometheus_http_response_size_bytes_sum{handler="/metrics"} 2.643421e+06
prometheus_http_response_size_bytes_count{handler="/metrics"} 229
# HELP prometheus_notifications_alertmanagers_discovered The number of alertmanagers discovered and active.
# TYPE prometheus_notifications_alertmanagers_discovered gauge
prometheus_notifications_alertmanagers_discovered 1
# HELP prometheus_notifications_dropped_total Total number of alerts dropped due to errors when sending to Alertmanager.
# TYPE prometheus_notifications_dropped_total counter
prometheus_notifications_dropped_total 0
# HELP prometheus_notifications_errors_total Total number of errors sending alert notifications.
# TYPE prometheus_notifications_errors_total counter
prometheus_notifications_errors_total{alertmanager="http://localhost:9010/health/api/v2/alerts"} 0
# HELP prometheus_notifications_latency_seconds Latency quantiles for sending alert notifications.
# TYPE prometheus_notifications_latency_seconds summary
prometheus_notifications_latency_seconds{alertmanager="http://localhost:9010/health/api/v2/alerts",quantile="0.5"} 0.000247125
prometheus_notifications_latency_seconds{alertmanager="http://localhost:9010/health/api/v2/alerts",quantile="0.9"} 0.000366189
prometheus_notifications_latency_seconds{alertmanager="http://localhost:9010/health/api/v2/alerts",quantile="0.99"} 0.000497647
prometheus_notifications_latency_seconds_sum{alertmanager="http://localhost:9010/health/api/v2/alerts"} 0.169265302
prometheus_notifications_latency_seconds_count{alertmanager="http://localhost:9010/health/api/v2/alerts"} 634
# HELP prometheus_notifications_queue_capacity The capacity of the alert notifications queue.
# TYPE prometheus_notifications_queue_capacity gauge
prometheus_notifications_queue_capacity 10000
# HELP prometheus_notifications_queue_length The number of alert notifications in the queue.
# TYPE prometheus_notifications_queue_length gauge
prometheus_notifications_queue_length 0
# HELP prometheus_notifications_sent_total Total number of alerts sent.
# TYPE prometheus_notifications_sent_total counter
prometheus_notifications_sent_total{alertmanager="http://localhost:9010/health/api/v2/alerts"} 906
# HELP prometheus_ready Whether Prometheus startup was fully completed and the server is ready for normal operation.
# TYPE prometheus_ready gauge
prometheus_ready 1
# HELP prometheus_remote_storage_bytes_total The total number of bytes of data (not metadata) sent by the queue after compression. Note that when exemplars over remote write is enabled the exemplars included in a remote write request count towards this metric.
# TYPE prometheus_remote_storage_bytes_total counter
prometheus_remote_storage_bytes_total{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 1.9884936e+07
# HELP prometheus_remote_storage_enqueue_retries_total Total number of times enqueue has failed because a shards queue was full.
# TYPE prometheus_remote_storage_enqueue_retries_total counter
prometheus_remote_storage_enqueue_retries_total{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 0
# HELP prometheus_remote_storage_exemplars_dropped_total Total number of exemplars which were dropped after being read from the WAL before being sent via remote write, either via relabelling or unintentionally because of an unknown reference ID.
# TYPE prometheus_remote_storage_exemplars_dropped_total counter
prometheus_remote_storage_exemplars_dropped_total{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 0
# HELP prometheus_remote_storage_exemplars_failed_total Total number of exemplars which failed on send to remote storage, non-recoverable errors.
# TYPE prometheus_remote_storage_exemplars_failed_total counter
prometheus_remote_storage_exemplars_failed_total{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 0
# HELP prometheus_remote_storage_exemplars_in_total Exemplars in to remote storage, compare to exemplars out for queue managers.
# TYPE prometheus_remote_storage_exemplars_in_total counter
prometheus_remote_storage_exemplars_in_total 0
# HELP prometheus_remote_storage_exemplars_pending The number of exemplars pending in the queues shards to be sent to the remote storage.
# TYPE prometheus_remote_storage_exemplars_pending gauge
prometheus_remote_storage_exemplars_pending{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 0
# HELP prometheus_remote_storage_exemplars_retried_total Total number of exemplars which failed on send to remote storage but were retried because the send error was recoverable.
# TYPE prometheus_remote_storage_exemplars_retried_total counter
prometheus_remote_storage_exemplars_retried_total{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 0
# HELP prometheus_remote_storage_exemplars_total Total number of exemplars sent to remote storage.
# TYPE prometheus_remote_storage_exemplars_total counter
prometheus_remote_storage_exemplars_total{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 0
# HELP prometheus_remote_storage_highest_timestamp_in_seconds Highest timestamp that has come into the remote storage via the Appender interface, in seconds since epoch.
# TYPE prometheus_remote_storage_highest_timestamp_in_seconds gauge
prometheus_remote_storage_highest_timestamp_in_seconds 1.727949672e+09
# HELP prometheus_remote_storage_histograms_dropped_total Total number of histograms which were dropped after being read from the WAL before being sent via remote write, either via relabelling or unintentionally because of an unknown reference ID.
# TYPE prometheus_remote_storage_histograms_dropped_total counter
prometheus_remote_storage_histograms_dropped_total{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 0
# HELP prometheus_remote_storage_histograms_failed_total Total number of histograms which failed on send to remote storage, non-recoverable errors.
# TYPE prometheus_remote_storage_histograms_failed_total counter
prometheus_remote_storage_histograms_failed_total{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 0
# HELP prometheus_remote_storage_histograms_in_total HistogramSamples in to remote storage, compare to histograms out for queue managers.
# TYPE prometheus_remote_storage_histograms_in_total counter
prometheus_remote_storage_histograms_in_total 0
# HELP prometheus_remote_storage_histograms_pending The number of histograms pending in the queues shards to be sent to the remote storage.
# TYPE prometheus_remote_storage_histograms_pending gauge
prometheus_remote_storage_histograms_pending{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 0
# HELP prometheus_remote_storage_histograms_retried_total Total number of histograms which failed on send to remote storage but were retried because the send error was recoverable.
# TYPE prometheus_remote_storage_histograms_retried_total counter
prometheus_remote_storage_histograms_retried_total{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 0
# HELP prometheus_remote_storage_histograms_total Total number of histograms sent to remote storage.
# TYPE prometheus_remote_storage_histograms_total counter
prometheus_remote_storage_histograms_total{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 0
# HELP prometheus_remote_storage_max_samples_per_send The maximum number of samples to be sent, in a single request, to the remote storage. Note that, when sending of exemplars over remote write is enabled, exemplars count towards this limt.
# TYPE prometheus_remote_storage_max_samples_per_send gauge
prometheus_remote_storage_max_samples_per_send{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 2000
# HELP prometheus_remote_storage_metadata_bytes_total The total number of bytes of metadata sent by the queue after compression.
# TYPE prometheus_remote_storage_metadata_bytes_total counter
prometheus_remote_storage_metadata_bytes_total{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 9.779213e+06
# HELP prometheus_remote_storage_metadata_failed_total Total number of metadata entries which failed on send to remote storage, non-recoverable errors.
# TYPE prometheus_remote_storage_metadata_failed_total counter
prometheus_remote_storage_metadata_failed_total{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 2094
# HELP prometheus_remote_storage_metadata_retried_total Total number of metadata entries which failed on send to remote storage but were retried because the send error was recoverable.
# TYPE prometheus_remote_storage_metadata_retried_total counter
prometheus_remote_storage_metadata_retried_total{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 0
# HELP prometheus_remote_storage_metadata_total Total number of metadata entries sent to remote storage.
# TYPE prometheus_remote_storage_metadata_total counter
prometheus_remote_storage_metadata_total{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 468281
# HELP prometheus_remote_storage_queue_highest_sent_timestamp_seconds Timestamp from a WAL sample, the highest timestamp successfully sent by this queue, in seconds since epoch.
# TYPE prometheus_remote_storage_queue_highest_sent_timestamp_seconds gauge
prometheus_remote_storage_queue_highest_sent_timestamp_seconds{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 1.727949672e+09
# HELP prometheus_remote_storage_samples_dropped_total Total number of samples which were dropped after being read from the WAL before being sent via remote write, either via relabelling or unintentionally because of an unknown reference ID.
# TYPE prometheus_remote_storage_samples_dropped_total counter
prometheus_remote_storage_samples_dropped_total{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 0
# HELP prometheus_remote_storage_samples_failed_total Total number of samples which failed on send to remote storage, non-recoverable errors.
# TYPE prometheus_remote_storage_samples_failed_total counter
prometheus_remote_storage_samples_failed_total{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 2894
# HELP prometheus_remote_storage_samples_in_total Samples in to remote storage, compare to samples out for queue managers.
# TYPE prometheus_remote_storage_samples_in_total counter
prometheus_remote_storage_samples_in_total 750834
# HELP prometheus_remote_storage_samples_pending The number of samples pending in the queues shards to be sent to the remote storage.
# TYPE prometheus_remote_storage_samples_pending gauge
prometheus_remote_storage_samples_pending{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 0
# HELP prometheus_remote_storage_samples_retried_total Total number of samples which failed on send to remote storage but were retried because the send error was recoverable.
# TYPE prometheus_remote_storage_samples_retried_total counter
prometheus_remote_storage_samples_retried_total{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 0
# HELP prometheus_remote_storage_samples_total Total number of samples sent to remote storage.
# TYPE prometheus_remote_storage_samples_total counter
prometheus_remote_storage_samples_total{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 742073
# HELP prometheus_remote_storage_sent_batch_duration_seconds Duration of send calls to the remote storage.
# TYPE prometheus_remote_storage_sent_batch_duration_seconds histogram
prometheus_remote_storage_sent_batch_duration_seconds_bucket{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0",le="0.005"} 0
prometheus_remote_storage_sent_batch_duration_seconds_bucket{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0",le="0.01"} 0
prometheus_remote_storage_sent_batch_duration_seconds_bucket{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0",le="0.025"} 0
prometheus_remote_storage_sent_batch_duration_seconds_bucket{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0",le="0.05"} 0
prometheus_remote_storage_sent_batch_duration_seconds_bucket{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0",le="0.1"} 5
prometheus_remote_storage_sent_batch_duration_seconds_bucket{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0",le="0.25"} 1536
prometheus_remote_storage_sent_batch_duration_seconds_bucket{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0",le="0.5"} 1539
prometheus_remote_storage_sent_batch_duration_seconds_bucket{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0",le="1"} 1543
prometheus_remote_storage_sent_batch_duration_seconds_bucket{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0",le="2.5"} 1544
prometheus_remote_storage_sent_batch_duration_seconds_bucket{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0",le="5"} 1544
prometheus_remote_storage_sent_batch_duration_seconds_bucket{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0",le="10"} 1544
prometheus_remote_storage_sent_batch_duration_seconds_bucket{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0",le="25"} 1544
prometheus_remote_storage_sent_batch_duration_seconds_bucket{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0",le="60"} 1544
prometheus_remote_storage_sent_batch_duration_seconds_bucket{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0",le="120"} 1544
prometheus_remote_storage_sent_batch_duration_seconds_bucket{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0",le="300"} 1544
prometheus_remote_storage_sent_batch_duration_seconds_bucket{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0",le="+Inf"} 1544
prometheus_remote_storage_sent_batch_duration_seconds_sum{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 228.94854348400023
prometheus_remote_storage_sent_batch_duration_seconds_count{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 1544
# HELP prometheus_remote_storage_shard_capacity The capacity of each shard of the queue used for parallel sending to the remote storage.
# TYPE prometheus_remote_storage_shard_capacity gauge
prometheus_remote_storage_shard_capacity{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 10000
# HELP prometheus_remote_storage_shards The number of shards used for parallel sending to the remote storage.
# TYPE prometheus_remote_storage_shards gauge
prometheus_remote_storage_shards{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 1
# HELP prometheus_remote_storage_shards_desired The number of shards that the queues shard calculation wants to run based on the rate of samples in vs. samples out.
# TYPE prometheus_remote_storage_shards_desired gauge
prometheus_remote_storage_shards_desired{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 0.009054950229540521
# HELP prometheus_remote_storage_shards_max The maximum number of shards that the queue is allowed to run.
# TYPE prometheus_remote_storage_shards_max gauge
prometheus_remote_storage_shards_max{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 50
# HELP prometheus_remote_storage_shards_min The minimum number of shards that the queue is allowed to run.
# TYPE prometheus_remote_storage_shards_min gauge
prometheus_remote_storage_shards_min{remote_name="10a14958-01f8-dd3c-d126-11111111111a",url="http://127.0.0.1:8989/v1/contexts/default/services/httpproxy?service-name=AIOps&api-type=AIOpsHealthMetrics&api-subtype=RemoteWrite&api-version=1.0"} 1
# HELP prometheus_remote_storage_string_interner_zero_reference_releases_total The number of times release has been called for strings that are not interned.
# TYPE prometheus_remote_storage_string_interner_zero_reference_releases_total counter
prometheus_remote_storage_string_interner_zero_reference_releases_total 0
# HELP prometheus_rule_evaluation_duration_seconds The duration for a rule to execute.
# TYPE prometheus_rule_evaluation_duration_seconds summary
prometheus_rule_evaluation_duration_seconds{quantile="0.5"} 0.000242592
prometheus_rule_evaluation_duration_seconds{quantile="0.9"} 0.000403223
prometheus_rule_evaluation_duration_seconds{quantile="0.99"} 0.000982636
prometheus_rule_evaluation_duration_seconds_sum 0.824532589
prometheus_rule_evaluation_duration_seconds_count 2988
# HELP prometheus_rule_evaluation_failures_total The total number of rule evaluation failures.
# TYPE prometheus_rule_evaluation_failures_total counter
prometheus_rule_evaluation_failures_total{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_cpu"} 0
prometheus_rule_evaluation_failures_total{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_hardware_stats_fmc"} 0
prometheus_rule_evaluation_failures_total{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_mu"} 0
prometheus_rule_evaluation_failures_total{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_web_server_stats"} 0
prometheus_rule_evaluation_failures_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_asp_drop"} 0
prometheus_rule_evaluation_failures_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_chassis_status_ftd"} 0
prometheus_rule_evaluation_failures_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_cpu"} 0
prometheus_rule_evaluation_failures_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_ftd_ha"} 0
prometheus_rule_evaluation_failures_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_mu"} 0
prometheus_rule_evaluation_failures_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_asp_drop"} 0
prometheus_rule_evaluation_failures_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_chassis_status_ftd"} 0
prometheus_rule_evaluation_failures_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_cpu"} 0
prometheus_rule_evaluation_failures_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_ftd_ha"} 0
prometheus_rule_evaluation_failures_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_mu"} 0
# HELP prometheus_rule_evaluations_total The total number of rule evaluations.
# TYPE prometheus_rule_evaluations_total counter
prometheus_rule_evaluations_total{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_cpu"} 0
prometheus_rule_evaluations_total{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_hardware_stats_fmc"} 276
prometheus_rule_evaluations_total{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_mu"} 138
prometheus_rule_evaluations_total{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_web_server_stats"} 92
prometheus_rule_evaluations_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_asp_drop"} 92
prometheus_rule_evaluations_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_chassis_status_ftd"} 90
prometheus_rule_evaluations_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_cpu"} 552
prometheus_rule_evaluations_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_ftd_ha"} 92
prometheus_rule_evaluations_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_mu"} 414
prometheus_rule_evaluations_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_asp_drop"} 92
prometheus_rule_evaluations_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_chassis_status_ftd"} 92
prometheus_rule_evaluations_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_cpu"} 552
prometheus_rule_evaluations_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_ftd_ha"} 92
prometheus_rule_evaluations_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_mu"} 414
# HELP prometheus_rule_group_duration_seconds The duration of rule group evaluations.
# TYPE prometheus_rule_group_duration_seconds summary
prometheus_rule_group_duration_seconds{quantile="0.01"} 2.304e-06
prometheus_rule_group_duration_seconds{quantile="0.05"} 2.856e-06
prometheus_rule_group_duration_seconds{quantile="0.5"} 0.000757494
prometheus_rule_group_duration_seconds{quantile="0.9"} 0.003908595
prometheus_rule_group_duration_seconds{quantile="0.99"} 0.004074301
prometheus_rule_group_duration_seconds_sum 0.836450286999999
prometheus_rule_group_duration_seconds_count 643
# HELP prometheus_rule_group_interval_seconds The interval of a rule group.
# TYPE prometheus_rule_group_interval_seconds gauge
prometheus_rule_group_interval_seconds{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_cpu"} 300
prometheus_rule_group_interval_seconds{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_hardware_stats_fmc"} 300
prometheus_rule_group_interval_seconds{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_mu"} 300
prometheus_rule_group_interval_seconds{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_web_server_stats"} 300
prometheus_rule_group_interval_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_asp_drop"}300
prometheus_rule_group_interval_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_chassis_status_ftd"} 300
prometheus_rule_group_interval_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_cpu"} 300
prometheus_rule_group_interval_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_ftd_ha"} 300
prometheus_rule_group_interval_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_mu"} 300
prometheus_rule_group_interval_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_asp_drop"}300
prometheus_rule_group_interval_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_chassis_status_ftd"} 300
prometheus_rule_group_interval_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_cpu"} 300
prometheus_rule_group_interval_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_ftd_ha"} 300
prometheus_rule_group_interval_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_mu"} 300
# HELP prometheus_rule_group_iterations_missed_total The total number of rule group evaluations missed due to slow rule group evaluation.
# TYPE prometheus_rule_group_iterations_missed_total counter
prometheus_rule_group_iterations_missed_total{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_cpu"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_hardware_stats_fmc"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_mu"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_web_server_stats"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_asp_drop"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_chassis_status_ftd"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_cpu"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_ftd_ha"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_mu"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_asp_drop"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_chassis_status_ftd"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_cpu"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_ftd_ha"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_mu"} 0
# HELP prometheus_rule_group_iterations_total The total number of scheduled rule group evaluations, whether executed or missed.
# TYPE prometheus_rule_group_iterations_total counter
prometheus_rule_group_iterations_total{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_cpu"} 46
prometheus_rule_group_iterations_total{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_hardware_stats_fmc"} 46
prometheus_rule_group_iterations_total{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_mu"} 46
prometheus_rule_group_iterations_total{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_web_server_stats"} 46
prometheus_rule_group_iterations_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_asp_drop"}46
prometheus_rule_group_iterations_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_chassis_status_ftd"} 45
prometheus_rule_group_iterations_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_cpu"} 46
prometheus_rule_group_iterations_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_ftd_ha"} 46
prometheus_rule_group_iterations_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_mu"} 46
prometheus_rule_group_iterations_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_asp_drop"}46
prometheus_rule_group_iterations_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_chassis_status_ftd"} 46
prometheus_rule_group_iterations_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_cpu"} 46
prometheus_rule_group_iterations_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_ftd_ha"} 46
prometheus_rule_group_iterations_total{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_mu"} 46
# HELP prometheus_rule_group_last_duration_seconds The duration of the last rule group evaluation.
# TYPE prometheus_rule_group_last_duration_seconds gauge
prometheus_rule_group_last_duration_seconds{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_cpu"} 2.856e-06
prometheus_rule_group_last_duration_seconds{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_hardware_stats_fmc"} 0.000817497
prometheus_rule_group_last_duration_seconds{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_mu"}0.000643541
prometheus_rule_group_last_duration_seconds{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_web_server_stats"} 0.000567317
prometheus_rule_group_last_duration_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_asp_drop"} 0.000442819
prometheus_rule_group_last_duration_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_chassis_status_ftd"} 0.000536066
prometheus_rule_group_last_duration_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_cpu"}0.004074301
prometheus_rule_group_last_duration_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_ftd_ha"} 0.000847602
prometheus_rule_group_last_duration_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_mu"} 0.002590853
prometheus_rule_group_last_duration_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_asp_drop"} 0.00043024
prometheus_rule_group_last_duration_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_chassis_status_ftd"} 0.000557614
prometheus_rule_group_last_duration_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_cpu"}0.003908595
prometheus_rule_group_last_duration_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_ftd_ha"} 0.000757494
prometheus_rule_group_last_duration_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_mu"} 0.002394066
# HELP prometheus_rule_group_last_evaluation_samples The number of samples returned during the last rule group evaluation.
# TYPE prometheus_rule_group_last_evaluation_samples gauge
prometheus_rule_group_last_evaluation_samples{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_cpu"} 0
prometheus_rule_group_last_evaluation_samples{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_hardware_stats_fmc"} 0
prometheus_rule_group_last_evaluation_samples{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_mu"} 0
prometheus_rule_group_last_evaluation_samples{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_web_server_stats"} 0
prometheus_rule_group_last_evaluation_samples{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_asp_drop"} 0
prometheus_rule_group_last_evaluation_samples{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_chassis_status_ftd"} 0
prometheus_rule_group_last_evaluation_samples{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_cpu"} 14
prometheus_rule_group_last_evaluation_samples{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_ftd_ha"} 0
prometheus_rule_group_last_evaluation_samples{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_mu"} 6
prometheus_rule_group_last_evaluation_samples{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_asp_drop"} 0
prometheus_rule_group_last_evaluation_samples{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_chassis_status_ftd"} 0
prometheus_rule_group_last_evaluation_samples{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_cpu"} 14
prometheus_rule_group_last_evaluation_samples{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_ftd_ha"} 0
prometheus_rule_group_last_evaluation_samples{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_mu"} 6
# HELP prometheus_rule_group_last_evaluation_timestamp_seconds The timestamp of the last rule group evaluation in seconds.
# TYPE prometheus_rule_group_last_evaluation_timestamp_seconds gauge
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_cpu"} 1.7279494707836647e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_hardware_stats_fmc"} 1.727949599127514e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_mu"} 1.7279494924714713e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_web_server_stats"} 1.7279495639798722e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_asp_drop"} 1.7279496865529916e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_chassis_status_ftd"} 1.7279493994283164e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_cpu"} 1.7279495622451158e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_ftd_ha"} 1.7279495564934978e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_mu"} 1.7279495703698833e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_asp_drop"} 1.727949452660702e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_chassis_status_ftd"} 1.7279495691696138e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_cpu"} 1.7279495355416694e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_ftd_ha"} 1.7279494536606548e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_mu"} 1.7279496538878825e+09
# HELP prometheus_rule_group_rules The number of rules.
# TYPE prometheus_rule_group_rules gauge
prometheus_rule_group_rules{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_cpu"} 0
prometheus_rule_group_rules{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_hardware_stats_fmc"}6
prometheus_rule_group_rules{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_mu"} 3
prometheus_rule_group_rules{rule_group="/var/opt/prometheus/mgmtrules/FirewallManagementCenterHealthPolicy_e458b606-45bb-11ef-83aa-b04a5479ad8f.yaml;hm_web_server_stats"} 2
prometheus_rule_group_rules{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_asp_drop"} 2
prometheus_rule_group_rules{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_chassis_status_ftd"} 2
prometheus_rule_group_rules{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_cpu"} 12
prometheus_rule_group_rules{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_ftd_ha"} 2
prometheus_rule_group_rules{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_7f32d900-3ea9-11ef-a7de-950358904bcb.yaml;hm_mu"} 9
prometheus_rule_group_rules{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_asp_drop"} 2
prometheus_rule_group_rules{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_chassis_status_ftd"} 2
prometheus_rule_group_rules{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_cpu"} 12
prometheus_rule_group_rules{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_ftd_ha"} 2
prometheus_rule_group_rules{rule_group="/var/opt/prometheus/rules/Initial_Health_Policy2024-05-1422:31:23_beef9d06-49aa-11ef-8322-c7dea3db6c57.yaml;hm_mu"} 9
# HELP prometheus_sd_azure_failures_total Number of Azure service discovery refresh failures.
# TYPE prometheus_sd_azure_failures_total counter
prometheus_sd_azure_failures_total 0
# HELP prometheus_sd_consul_rpc_duration_seconds The duration of a Consul RPC call in seconds.
# TYPE prometheus_sd_consul_rpc_duration_seconds summary
prometheus_sd_consul_rpc_duration_seconds{call="service",endpoint="catalog",quantile="0.5"} NaN
prometheus_sd_consul_rpc_duration_seconds{call="service",endpoint="catalog",quantile="0.9"} NaN
prometheus_sd_consul_rpc_duration_seconds{call="service",endpoint="catalog",quantile="0.99"} NaN
prometheus_sd_consul_rpc_duration_seconds_sum{call="service",endpoint="catalog"} 0
prometheus_sd_consul_rpc_duration_seconds_count{call="service",endpoint="catalog"} 0
prometheus_sd_consul_rpc_duration_seconds{call="services",endpoint="catalog",quantile="0.5"} NaN
prometheus_sd_consul_rpc_duration_seconds{call="services",endpoint="catalog",quantile="0.9"} NaN
prometheus_sd_consul_rpc_duration_seconds{call="services",endpoint="catalog",quantile="0.99"} NaN
prometheus_sd_consul_rpc_duration_seconds_sum{call="services",endpoint="catalog"} 0
prometheus_sd_consul_rpc_duration_seconds_count{call="services",endpoint="catalog"} 0
# HELP prometheus_sd_consul_rpc_failures_total The number of Consul RPC call failures.
# TYPE prometheus_sd_consul_rpc_failures_total counter
prometheus_sd_consul_rpc_failures_total 0
# HELP prometheus_sd_discovered_targets Current number of discovered targets.
# TYPE prometheus_sd_discovered_targets gauge
prometheus_sd_discovered_targets{config="config-0",name="notify"} 1
prometheus_sd_discovered_targets{config="prometheus",name="scrape"} 3
# HELP prometheus_sd_dns_lookup_failures_total The number of DNS-SD lookup failures.
# TYPE prometheus_sd_dns_lookup_failures_total counter
prometheus_sd_dns_lookup_failures_total 0
# HELP prometheus_sd_dns_lookups_total The number of DNS-SD lookups.
# TYPE prometheus_sd_dns_lookups_total counter
prometheus_sd_dns_lookups_total 0
# HELP prometheus_sd_failed_configs Current number of service discovery configurations that failed to load.
# TYPE prometheus_sd_failed_configs gauge
prometheus_sd_failed_configs{name="notify"} 0
prometheus_sd_failed_configs{name="scrape"} 0
# HELP prometheus_sd_file_mtime_seconds Timestamp (mtime) of files read by FileSD. Timestamp is set at read time.
# TYPE prometheus_sd_file_mtime_seconds gauge
prometheus_sd_file_mtime_seconds{filename="/var/opt/prometheus/targets/7f32d900-3ea9-11ef-a7de-950358904bcb_127.0.0.2.json"} 1.727949582e+09
prometheus_sd_file_mtime_seconds{filename="/var/opt/prometheus/targets/beef9d06-49aa-11ef-8322-c7dea3db6c57_127.0.0.4.json"} 1.721819236e+09
# HELP prometheus_sd_file_read_errors_total The number of File-SD read errors.
# TYPE prometheus_sd_file_read_errors_total counter
prometheus_sd_file_read_errors_total 0
# HELP prometheus_sd_file_scan_duration_seconds The duration of the File-SD scan in seconds.
# TYPE prometheus_sd_file_scan_duration_seconds summary
prometheus_sd_file_scan_duration_seconds{quantile="0.5"} 0.005096733
prometheus_sd_file_scan_duration_seconds{quantile="0.9"} 0.006892784
prometheus_sd_file_scan_duration_seconds{quantile="0.99"} 0.007181469
prometheus_sd_file_scan_duration_seconds_sum 2.2883371260000027
prometheus_sd_file_scan_duration_seconds_count 388
# HELP prometheus_sd_file_watcher_errors_total The number of File-SD errors caused by filesystem watch failures.
# TYPE prometheus_sd_file_watcher_errors_total counter
prometheus_sd_file_watcher_errors_total 0
# HELP prometheus_sd_http_failures_total Number of HTTP service discovery refresh failures.
# TYPE prometheus_sd_http_failures_total counter
prometheus_sd_http_failures_total 0
# HELP prometheus_sd_kubernetes_events_total The number of Kubernetes events handled.
# TYPE prometheus_sd_kubernetes_events_total counter
prometheus_sd_kubernetes_events_total{event="add",role="endpoints"} 0
prometheus_sd_kubernetes_events_total{event="add",role="endpointslice"} 0
prometheus_sd_kubernetes_events_total{event="add",role="ingress"} 0
prometheus_sd_kubernetes_events_total{event="add",role="node"} 0
prometheus_sd_kubernetes_events_total{event="add",role="pod"} 0
prometheus_sd_kubernetes_events_total{event="add",role="service"} 0
prometheus_sd_kubernetes_events_total{event="delete",role="endpoints"} 0
prometheus_sd_kubernetes_events_total{event="delete",role="endpointslice"} 0
prometheus_sd_kubernetes_events_total{event="delete",role="ingress"} 0
prometheus_sd_kubernetes_events_total{event="delete",role="node"} 0
prometheus_sd_kubernetes_events_total{event="delete",role="pod"} 0
prometheus_sd_kubernetes_events_total{event="delete",role="service"} 0
prometheus_sd_kubernetes_events_total{event="update",role="endpoints"} 0
prometheus_sd_kubernetes_events_total{event="update",role="endpointslice"} 0
prometheus_sd_kubernetes_events_total{event="update",role="ingress"} 0
prometheus_sd_kubernetes_events_total{event="update",role="node"} 0
prometheus_sd_kubernetes_events_total{event="update",role="pod"} 0
prometheus_sd_kubernetes_events_total{event="update",role="service"} 0
# HELP prometheus_sd_kuma_fetch_duration_seconds The duration of a Kuma MADS fetch call.
# TYPE prometheus_sd_kuma_fetch_duration_seconds summary
prometheus_sd_kuma_fetch_duration_seconds{quantile="0.5"} NaN
prometheus_sd_kuma_fetch_duration_seconds{quantile="0.9"} NaN
prometheus_sd_kuma_fetch_duration_seconds{quantile="0.99"} NaN
prometheus_sd_kuma_fetch_duration_seconds_sum 0
prometheus_sd_kuma_fetch_duration_seconds_count 0
# HELP prometheus_sd_kuma_fetch_failures_total The number of Kuma MADS fetch call failures.
# TYPE prometheus_sd_kuma_fetch_failures_total counter
prometheus_sd_kuma_fetch_failures_total 0
# HELP prometheus_sd_kuma_fetch_skipped_updates_total The number of Kuma MADS fetch calls that result in no updates to the targets.
# TYPE prometheus_sd_kuma_fetch_skipped_updates_total counter
prometheus_sd_kuma_fetch_skipped_updates_total 0
# HELP prometheus_sd_linode_failures_total Number of Linode service discovery refresh failures.
# TYPE prometheus_sd_linode_failures_total counter
prometheus_sd_linode_failures_total 0
# HELP prometheus_sd_nomad_failures_total Number of nomad service discovery refresh failures.
# TYPE prometheus_sd_nomad_failures_total counter
prometheus_sd_nomad_failures_total 0
# HELP prometheus_sd_received_updates_total Total number of update events received from the SD providers.
# TYPE prometheus_sd_received_updates_total counter
prometheus_sd_received_updates_total{name="notify"} 2
prometheus_sd_received_updates_total{name="scrape"} 778
# HELP prometheus_sd_updates_total Total number of update events sent to the SD consumers.
# TYPE prometheus_sd_updates_total counter
prometheus_sd_updates_total{name="notify"} 1
prometheus_sd_updates_total{name="scrape"} 163
# HELP prometheus_target_interval_length_seconds Actual intervals between scrapes.
# TYPE prometheus_target_interval_length_seconds summary
prometheus_target_interval_length_seconds{interval="1m0s",quantile="0.01"} 59.999288801
prometheus_target_interval_length_seconds{interval="1m0s",quantile="0.05"} 59.999437385
prometheus_target_interval_length_seconds{interval="1m0s",quantile="0.5"} 60.000012922
prometheus_target_interval_length_seconds{interval="1m0s",quantile="0.9"} 60.000392048
prometheus_target_interval_length_seconds{interval="1m0s",quantile="0.99"} 60.000767828
prometheus_target_interval_length_seconds_sum{interval="1m0s"} 40680.010128757014
prometheus_target_interval_length_seconds_count{interval="1m0s"} 678
# HELP prometheus_target_metadata_cache_bytes The number of bytes that are currently used for storing metric metadata in the cache
# TYPE prometheus_target_metadata_cache_bytes gauge
prometheus_target_metadata_cache_bytes{scrape_job="prometheus"} 72568
# HELP prometheus_target_metadata_cache_entries Total number of metric metadata entries in the cache
# TYPE prometheus_target_metadata_cache_entries gauge
prometheus_target_metadata_cache_entries{scrape_job="prometheus"} 2129
# HELP prometheus_target_scrape_pool_exceeded_label_limits_total Total number of times scrape pools hit the label limits, during sync or config reload.
# TYPE prometheus_target_scrape_pool_exceeded_label_limits_total counter
prometheus_target_scrape_pool_exceeded_label_limits_total 0
# HELP prometheus_target_scrape_pool_exceeded_target_limit_total Total number of times scrape pools hit the target limit, during sync or config reload.
# TYPE prometheus_target_scrape_pool_exceeded_target_limit_total counter
prometheus_target_scrape_pool_exceeded_target_limit_total 0
# HELP prometheus_target_scrape_pool_reloads_failed_total Total number of failed scrape pool reloads.
# TYPE prometheus_target_scrape_pool_reloads_failed_total counter
prometheus_target_scrape_pool_reloads_failed_total 0
# HELP prometheus_target_scrape_pool_reloads_total Total number of scrape pool reloads.
# TYPE prometheus_target_scrape_pool_reloads_total counter
prometheus_target_scrape_pool_reloads_total 0
# HELP prometheus_target_scrape_pool_sync_total Total number of syncs that were executed on a scrape pool.
# TYPE prometheus_target_scrape_pool_sync_total counter
prometheus_target_scrape_pool_sync_total{scrape_job="prometheus"} 163
# HELP prometheus_target_scrape_pool_target_limit Maximum number of targets allowed in this scrape pool.
# TYPE prometheus_target_scrape_pool_target_limit gauge
prometheus_target_scrape_pool_target_limit{scrape_job="prometheus"} 0
# HELP prometheus_target_scrape_pool_targets Current number of targets in this scrape pool.
# TYPE prometheus_target_scrape_pool_targets gauge
prometheus_target_scrape_pool_targets{scrape_job="prometheus"} 3
# HELP prometheus_target_scrape_pools_failed_total Total number of scrape pool creations that failed.
# TYPE prometheus_target_scrape_pools_failed_total counter
prometheus_target_scrape_pools_failed_total 0
# HELP prometheus_target_scrape_pools_total Total number of scrape pool creation attempts.
# TYPE prometheus_target_scrape_pools_total counter
prometheus_target_scrape_pools_total 1
# HELP prometheus_target_scrapes_cache_flush_forced_total How many times a scrape cache was flushed due to getting big while scrapes are failing.
# TYPE prometheus_target_scrapes_cache_flush_forced_total counter
prometheus_target_scrapes_cache_flush_forced_total 0
# HELP prometheus_target_scrapes_exceeded_body_size_limit_total Total number of scrapes that hit the body size limit
# TYPE prometheus_target_scrapes_exceeded_body_size_limit_total counter
prometheus_target_scrapes_exceeded_body_size_limit_total 0
# HELP prometheus_target_scrapes_exceeded_native_histogram_bucket_limit_total Total number of scrapes that hit the native histogram bucket limit and were rejected.
# TYPE prometheus_target_scrapes_exceeded_native_histogram_bucket_limit_total counter
prometheus_target_scrapes_exceeded_native_histogram_bucket_limit_total 0
# HELP prometheus_target_scrapes_exceeded_sample_limit_total Total number of scrapes that hit the sample limit and were rejected.
# TYPE prometheus_target_scrapes_exceeded_sample_limit_total counter
prometheus_target_scrapes_exceeded_sample_limit_total 0
# HELP prometheus_target_scrapes_exemplar_out_of_order_total Total number of exemplar rejected due to not being out of the expected order.
# TYPE prometheus_target_scrapes_exemplar_out_of_order_total counter
prometheus_target_scrapes_exemplar_out_of_order_total 0
# HELP prometheus_target_scrapes_sample_duplicate_timestamp_total Total number of samples rejected due to duplicate timestamps but different values.
# TYPE prometheus_target_scrapes_sample_duplicate_timestamp_total counter
prometheus_target_scrapes_sample_duplicate_timestamp_total 0
# HELP prometheus_target_scrapes_sample_out_of_bounds_total Total number of samples rejected due to timestamp falling outside of the time bounds.
# TYPE prometheus_target_scrapes_sample_out_of_bounds_total counter
prometheus_target_scrapes_sample_out_of_bounds_total 0
# HELP prometheus_target_scrapes_sample_out_of_order_total Total number of samples rejected due to not being out of the expected order.
# TYPE prometheus_target_scrapes_sample_out_of_order_total counter
prometheus_target_scrapes_sample_out_of_order_total 0
# HELP prometheus_target_sync_failed_total Total number of target sync failures.
# TYPE prometheus_target_sync_failed_total counter
prometheus_target_sync_failed_total{scrape_job="prometheus"} 0
# HELP prometheus_target_sync_length_seconds Actual interval to sync the scrape pool.
# TYPE prometheus_target_sync_length_seconds summary
prometheus_target_sync_length_seconds{scrape_job="prometheus",quantile="0.01"} 5.0172e-05
prometheus_target_sync_length_seconds{scrape_job="prometheus",quantile="0.05"} 5.0172e-05
prometheus_target_sync_length_seconds{scrape_job="prometheus",quantile="0.5"} 5.4405e-05
prometheus_target_sync_length_seconds{scrape_job="prometheus",quantile="0.9"} 6.7167e-05
prometheus_target_sync_length_seconds{scrape_job="prometheus",quantile="0.99"} 6.7167e-05
prometheus_target_sync_length_seconds_sum{scrape_job="prometheus"} 0.009638650000000006
prometheus_target_sync_length_seconds_count{scrape_job="prometheus"} 163
# HELP prometheus_template_text_expansion_failures_total The total number of template text expansion failures.
# TYPE prometheus_template_text_expansion_failures_total counter
prometheus_template_text_expansion_failures_total 0
# HELP prometheus_template_text_expansions_total The total number of template text expansions.
# TYPE prometheus_template_text_expansions_total counter
prometheus_template_text_expansions_total 6440
# HELP prometheus_treecache_watcher_goroutines The current number of watcher goroutines.
# TYPE prometheus_treecache_watcher_goroutines gauge
prometheus_treecache_watcher_goroutines 0
# HELP prometheus_treecache_zookeeper_failures_total The total number of ZooKeeper failures.
# TYPE prometheus_treecache_zookeeper_failures_total counter
prometheus_treecache_zookeeper_failures_total 0
# HELP prometheus_tsdb_blocks_loaded Number of currently loaded data blocks
# TYPE prometheus_tsdb_blocks_loaded gauge
prometheus_tsdb_blocks_loaded 8
# HELP prometheus_tsdb_checkpoint_creations_failed_total Total number of checkpoint creations that failed.
# TYPE prometheus_tsdb_checkpoint_creations_failed_total counter
prometheus_tsdb_checkpoint_creations_failed_total 0
# HELP prometheus_tsdb_checkpoint_creations_total Total number of checkpoint creations attempted.
# TYPE prometheus_tsdb_checkpoint_creations_total counter
prometheus_tsdb_checkpoint_creations_total 2
# HELP prometheus_tsdb_checkpoint_deletions_failed_total Total number of checkpoint deletions that failed.
# TYPE prometheus_tsdb_checkpoint_deletions_failed_total counter
prometheus_tsdb_checkpoint_deletions_failed_total 0
# HELP prometheus_tsdb_checkpoint_deletions_total Total number of checkpoint deletions attempted.
# TYPE prometheus_tsdb_checkpoint_deletions_total counter
prometheus_tsdb_checkpoint_deletions_total 2
# HELP prometheus_tsdb_clean_start -1: lockfile is disabled. 0: a lockfile from a previous execution was replaced. 1: lockfile creation was clean
# TYPE prometheus_tsdb_clean_start gauge
prometheus_tsdb_clean_start 1
# HELP prometheus_tsdb_compaction_chunk_range_seconds Final time range of chunks on their first compaction
# TYPE prometheus_tsdb_compaction_chunk_range_seconds histogram
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="100"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="400"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="1600"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="6400"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="25600"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="102400"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="409600"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="1.6384e+06"} 24
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="6.5536e+06"} 13360
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="2.62144e+07"} 16676
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="+Inf"} 16676
prometheus_tsdb_compaction_chunk_range_seconds_sum 9.3405873975e+10
prometheus_tsdb_compaction_chunk_range_seconds_count 16676
# HELP prometheus_tsdb_compaction_chunk_samples Final number of samples on their first compaction
# TYPE prometheus_tsdb_compaction_chunk_samples histogram
prometheus_tsdb_compaction_chunk_samples_bucket{le="4"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="6"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="9"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="13.5"} 1924
prometheus_tsdb_compaction_chunk_samples_bucket{le="20.25"} 3946
prometheus_tsdb_compaction_chunk_samples_bucket{le="30.375"} 9644
prometheus_tsdb_compaction_chunk_samples_bucket{le="45.5625"} 9783
prometheus_tsdb_compaction_chunk_samples_bucket{le="68.34375"} 11084
prometheus_tsdb_compaction_chunk_samples_bucket{le="102.515625"} 14265
prometheus_tsdb_compaction_chunk_samples_bucket{le="153.7734375"} 16676
prometheus_tsdb_compaction_chunk_samples_bucket{le="230.66015625"} 16676
prometheus_tsdb_compaction_chunk_samples_bucket{le="345.990234375"} 16676
prometheus_tsdb_compaction_chunk_samples_bucket{le="+Inf"} 16676
prometheus_tsdb_compaction_chunk_samples_sum 843182
prometheus_tsdb_compaction_chunk_samples_count 16676
# HELP prometheus_tsdb_compaction_chunk_size_bytes Final size of chunks on their first compaction
# TYPE prometheus_tsdb_compaction_chunk_size_bytes histogram
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="32"} 224
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="48"} 3687
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="72"} 11787
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="108"} 11928
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="162"} 12922
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="243"} 15050
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="364.5"} 16359
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="546.75"} 16526
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="820.125"} 16645
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="1230.1875"} 16676
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="1845.28125"} 16676
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="2767.921875"} 16676
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="+Inf"} 16676
prometheus_tsdb_compaction_chunk_size_bytes_sum 1.764299e+06
prometheus_tsdb_compaction_chunk_size_bytes_count 16676
# HELP prometheus_tsdb_compaction_duration_seconds Duration of compaction runs
# TYPE prometheus_tsdb_compaction_duration_seconds histogram
prometheus_tsdb_compaction_duration_seconds_bucket{le="1"} 10
prometheus_tsdb_compaction_duration_seconds_bucket{le="2"} 10
prometheus_tsdb_compaction_duration_seconds_bucket{le="4"} 10
prometheus_tsdb_compaction_duration_seconds_bucket{le="8"} 10
prometheus_tsdb_compaction_duration_seconds_bucket{le="16"} 10
prometheus_tsdb_compaction_duration_seconds_bucket{le="32"} 10
prometheus_tsdb_compaction_duration_seconds_bucket{le="64"} 10
prometheus_tsdb_compaction_duration_seconds_bucket{le="128"} 10
prometheus_tsdb_compaction_duration_seconds_bucket{le="256"} 10
prometheus_tsdb_compaction_duration_seconds_bucket{le="512"} 10
prometheus_tsdb_compaction_duration_seconds_bucket{le="1024"} 10
prometheus_tsdb_compaction_duration_seconds_bucket{le="2048"} 10
prometheus_tsdb_compaction_duration_seconds_bucket{le="4096"} 10
prometheus_tsdb_compaction_duration_seconds_bucket{le="8192"} 10
prometheus_tsdb_compaction_duration_seconds_bucket{le="+Inf"} 10
prometheus_tsdb_compaction_duration_seconds_sum 1.021549032
prometheus_tsdb_compaction_duration_seconds_count 10
# HELP prometheus_tsdb_compaction_populating_block Set to 1 when a block is currently being written to the disk.
# TYPE prometheus_tsdb_compaction_populating_block gauge
prometheus_tsdb_compaction_populating_block 0
# HELP prometheus_tsdb_compactions_failed_total Total number of compactions that failed for the partition.
# TYPE prometheus_tsdb_compactions_failed_total counter
prometheus_tsdb_compactions_failed_total 0
# HELP prometheus_tsdb_compactions_skipped_total Total number of skipped compactions due to disabled auto compaction.
# TYPE prometheus_tsdb_compactions_skipped_total counter
prometheus_tsdb_compactions_skipped_total 0
# HELP prometheus_tsdb_compactions_total Total number of compactions that were executed for the partition.
# TYPE prometheus_tsdb_compactions_total counter
prometheus_tsdb_compactions_total 10
# HELP prometheus_tsdb_compactions_triggered_total Total number of triggered compactions for the partition.
# TYPE prometheus_tsdb_compactions_triggered_total counter
prometheus_tsdb_compactions_triggered_total 231
# HELP prometheus_tsdb_data_replay_duration_seconds Time taken to replay the data on disk.
# TYPE prometheus_tsdb_data_replay_duration_seconds gauge
prometheus_tsdb_data_replay_duration_seconds 0.065773237
# HELP prometheus_tsdb_exemplar_exemplars_appended_total Total number of appended exemplars.
# TYPE prometheus_tsdb_exemplar_exemplars_appended_total counter
prometheus_tsdb_exemplar_exemplars_appended_total 0
# HELP prometheus_tsdb_exemplar_exemplars_in_storage Number of exemplars currently in circular storage.
# TYPE prometheus_tsdb_exemplar_exemplars_in_storage gauge
prometheus_tsdb_exemplar_exemplars_in_storage 0
# HELP prometheus_tsdb_exemplar_last_exemplars_timestamp_seconds The timestamp of the oldest exemplar stored in circular storage. Useful to check for what timerange the current exemplar buffer limit allows. This usually means the last timestampfor all exemplars for a typical setup. This is not true though if one of the series timestamp is in future compared to rest series.
# TYPE prometheus_tsdb_exemplar_last_exemplars_timestamp_seconds gauge
prometheus_tsdb_exemplar_last_exemplars_timestamp_seconds 0
# HELP prometheus_tsdb_exemplar_max_exemplars Total number of exemplars the exemplar storage can store, resizeable.
# TYPE prometheus_tsdb_exemplar_max_exemplars gauge
prometheus_tsdb_exemplar_max_exemplars 0
# HELP prometheus_tsdb_exemplar_out_of_order_exemplars_total Total number of out of order exemplar ingestion failed attempts.
# TYPE prometheus_tsdb_exemplar_out_of_order_exemplars_total counter
prometheus_tsdb_exemplar_out_of_order_exemplars_total 0
# HELP prometheus_tsdb_exemplar_series_with_exemplars_in_storage Number of series with exemplars currently in circular storage.
# TYPE prometheus_tsdb_exemplar_series_with_exemplars_in_storage gauge
prometheus_tsdb_exemplar_series_with_exemplars_in_storage 0
# HELP prometheus_tsdb_head_active_appenders Number of currently active appender transactions
# TYPE prometheus_tsdb_head_active_appenders gauge
prometheus_tsdb_head_active_appenders 0
# HELP prometheus_tsdb_head_chunks Total number of chunks in the head block.
# TYPE prometheus_tsdb_head_chunks gauge
prometheus_tsdb_head_chunks 4384
# HELP prometheus_tsdb_head_chunks_created_total Total number of chunks created in the head
# TYPE prometheus_tsdb_head_chunks_created_total counter
prometheus_tsdb_head_chunks_created_total 14404
# HELP prometheus_tsdb_head_chunks_removed_total Total number of chunks removed in the head
# TYPE prometheus_tsdb_head_chunks_removed_total counter
prometheus_tsdb_head_chunks_removed_total 10020
# HELP prometheus_tsdb_head_chunks_storage_size_bytes Size of the chunks_head directory.
# TYPE prometheus_tsdb_head_chunks_storage_size_bytes gauge
prometheus_tsdb_head_chunks_storage_size_bytes 625845
# HELP prometheus_tsdb_head_gc_duration_seconds Runtime of garbage collection in the head block.
# TYPE prometheus_tsdb_head_gc_duration_seconds summary
prometheus_tsdb_head_gc_duration_seconds_sum 0.011066007
prometheus_tsdb_head_gc_duration_seconds_count 4
# HELP prometheus_tsdb_head_max_time Maximum timestamp of the head block. The unit is decided by the library consumer.
# TYPE prometheus_tsdb_head_max_time gauge
prometheus_tsdb_head_max_time 1.727949672108e+12
# HELP prometheus_tsdb_head_max_time_seconds Maximum timestamp of the head block.
# TYPE prometheus_tsdb_head_max_time_seconds gauge
prometheus_tsdb_head_max_time_seconds 1.727949672e+09
# HELP prometheus_tsdb_head_min_time Minimum time bound of the head block. The unit is decided by the library consumer.
# TYPE prometheus_tsdb_head_min_time gauge
prometheus_tsdb_head_min_time 1.7279424e+12
# HELP prometheus_tsdb_head_min_time_seconds Minimum time bound of the head block.
# TYPE prometheus_tsdb_head_min_time_seconds gauge
prometheus_tsdb_head_min_time_seconds 1.7279424e+09
# HELP prometheus_tsdb_head_out_of_order_samples_appended_total Total number of appended out of order samples.
# TYPE prometheus_tsdb_head_out_of_order_samples_appended_total counter
prometheus_tsdb_head_out_of_order_samples_appended_total 0
# HELP prometheus_tsdb_head_samples_appended_total Total number of appended samples.
# TYPE prometheus_tsdb_head_samples_appended_total counter
prometheus_tsdb_head_samples_appended_total{type="float"} 409774
prometheus_tsdb_head_samples_appended_total{type="histogram"} 0
# HELP prometheus_tsdb_head_series Total number of series in the head block.
# TYPE prometheus_tsdb_head_series gauge
prometheus_tsdb_head_series 3364
# HELP prometheus_tsdb_head_series_created_total Total number of series created in the head
# TYPE prometheus_tsdb_head_series_created_total counter
prometheus_tsdb_head_series_created_total 6322
# HELP prometheus_tsdb_head_series_not_found_total Total number of requests for series that were not found.
# TYPE prometheus_tsdb_head_series_not_found_total counter
prometheus_tsdb_head_series_not_found_total 0
# HELP prometheus_tsdb_head_series_removed_total Total number of series removed in the head
# TYPE prometheus_tsdb_head_series_removed_total counter
prometheus_tsdb_head_series_removed_total 2958
# HELP prometheus_tsdb_head_truncations_failed_total Total number of head truncations that failed.
# TYPE prometheus_tsdb_head_truncations_failed_total counter
prometheus_tsdb_head_truncations_failed_total 0
# HELP prometheus_tsdb_head_truncations_total Total number of head truncations attempted.
# TYPE prometheus_tsdb_head_truncations_total counter
prometheus_tsdb_head_truncations_total 4
# HELP prometheus_tsdb_isolation_high_watermark The highest TSDB append ID that has been given out.
# TYPE prometheus_tsdb_isolation_high_watermark gauge
prometheus_tsdb_isolation_high_watermark 3679
# HELP prometheus_tsdb_isolation_low_watermark The lowest TSDB append ID that is still referenced.
# TYPE prometheus_tsdb_isolation_low_watermark gauge
prometheus_tsdb_isolation_low_watermark 3679
# HELP prometheus_tsdb_lowest_timestamp Lowest timestamp value stored in the database. The unit is decided by the library consumer.
# TYPE prometheus_tsdb_lowest_timestamp gauge
prometheus_tsdb_lowest_timestamp 1.721397312108e+12
# HELP prometheus_tsdb_lowest_timestamp_seconds Lowest timestamp value stored in the database.
# TYPE prometheus_tsdb_lowest_timestamp_seconds gauge
prometheus_tsdb_lowest_timestamp_seconds 1.721397312e+09
# HELP prometheus_tsdb_mmap_chunk_corruptions_total Total number of memory-mapped chunk corruptions.
# TYPE prometheus_tsdb_mmap_chunk_corruptions_total counter
prometheus_tsdb_mmap_chunk_corruptions_total 0
# HELP prometheus_tsdb_out_of_bound_samples_total Total number of out of bound samples ingestion failed attempts with out of order support disabled.
# TYPE prometheus_tsdb_out_of_bound_samples_total counter
prometheus_tsdb_out_of_bound_samples_total{type="float"} 0
# HELP prometheus_tsdb_out_of_order_samples_total Total number of out of order samples ingestion failed attempts due to out of order being disabled.
# TYPE prometheus_tsdb_out_of_order_samples_total counter
prometheus_tsdb_out_of_order_samples_total{type="float"} 25
prometheus_tsdb_out_of_order_samples_total{type="histogram"} 0
# HELP prometheus_tsdb_reloads_failures_total Number of times the database failed to reloadBlocks block data from disk.
# TYPE prometheus_tsdb_reloads_failures_total counter
prometheus_tsdb_reloads_failures_total 0
# HELP prometheus_tsdb_reloads_total Number of times the database reloaded block data from disk.
# TYPE prometheus_tsdb_reloads_total counter
prometheus_tsdb_reloads_total 237
# HELP prometheus_tsdb_retention_limit_bytes Max number of bytes to be retained in the tsdb blocks, configured 0 means disabled
# TYPE prometheus_tsdb_retention_limit_bytes gauge
prometheus_tsdb_retention_limit_bytes 1.34217728e+09
# HELP prometheus_tsdb_size_retentions_total The number of times that blocks were deleted because the maximum number of bytes was exceeded.
# TYPE prometheus_tsdb_size_retentions_total counter
prometheus_tsdb_size_retentions_total 0
# HELP prometheus_tsdb_snapshot_replay_error_total Total number snapshot replays that failed.
# TYPE prometheus_tsdb_snapshot_replay_error_total counter
prometheus_tsdb_snapshot_replay_error_total 0
# HELP prometheus_tsdb_storage_blocks_bytes The number of bytes that are currently used for local storage by all blocks.
# TYPE prometheus_tsdb_storage_blocks_bytes gauge
prometheus_tsdb_storage_blocks_bytes 3.41696566e+08
# HELP prometheus_tsdb_symbol_table_size_bytes Size of symbol table in memory for loaded blocks
# TYPE prometheus_tsdb_symbol_table_size_bytes gauge
prometheus_tsdb_symbol_table_size_bytes 5168
# HELP prometheus_tsdb_time_retentions_total The number of times that blocks were deleted because the maximum time limit was exceeded.
# TYPE prometheus_tsdb_time_retentions_total counter
prometheus_tsdb_time_retentions_total 0
# HELP prometheus_tsdb_tombstone_cleanup_seconds The time taken to recompact blocks to remove tombstones.
# TYPE prometheus_tsdb_tombstone_cleanup_seconds histogram
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="0.005"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="0.01"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="0.025"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="0.05"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="0.1"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="0.25"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="0.5"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="1"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="2.5"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="5"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="10"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="+Inf"} 0
prometheus_tsdb_tombstone_cleanup_seconds_sum 0
prometheus_tsdb_tombstone_cleanup_seconds_count 0
# HELP prometheus_tsdb_too_old_samples_total Total number of out of order samples ingestion failed attempts with out of support enabled, but sample outside of time window.
# TYPE prometheus_tsdb_too_old_samples_total counter
prometheus_tsdb_too_old_samples_total{type="float"} 0
# HELP prometheus_tsdb_vertical_compactions_total Total number of compactions done on overlapping blocks.
# TYPE prometheus_tsdb_vertical_compactions_total counter
prometheus_tsdb_vertical_compactions_total 0
# HELP prometheus_tsdb_wal_completed_pages_total Total number of completed pages.
# TYPE prometheus_tsdb_wal_completed_pages_total counter
prometheus_tsdb_wal_completed_pages_total 128
# HELP prometheus_tsdb_wal_corruptions_total Total number of WAL corruptions.
# TYPE prometheus_tsdb_wal_corruptions_total counter
prometheus_tsdb_wal_corruptions_total 0
# HELP prometheus_tsdb_wal_fsync_duration_seconds Duration of write log fsync.
# TYPE prometheus_tsdb_wal_fsync_duration_seconds summary
prometheus_tsdb_wal_fsync_duration_seconds{quantile="0.5"} NaN
prometheus_tsdb_wal_fsync_duration_seconds{quantile="0.9"} NaN
prometheus_tsdb_wal_fsync_duration_seconds{quantile="0.99"} NaN
prometheus_tsdb_wal_fsync_duration_seconds_sum 0.009036687
prometheus_tsdb_wal_fsync_duration_seconds_count 3
# HELP prometheus_tsdb_wal_page_flushes_total Total number of page flushes.
# TYPE prometheus_tsdb_wal_page_flushes_total counter
prometheus_tsdb_wal_page_flushes_total 1450
# HELP prometheus_tsdb_wal_segment_current Write log segment index that TSDB is currently writing to.
# TYPE prometheus_tsdb_wal_segment_current gauge
prometheus_tsdb_wal_segment_current 852
# HELP prometheus_tsdb_wal_storage_size_bytes Size of the write log directory.
# TYPE prometheus_tsdb_wal_storage_size_bytes gauge
prometheus_tsdb_wal_storage_size_bytes 4.226934e+06
# HELP prometheus_tsdb_wal_truncate_duration_seconds Duration of WAL truncation.
# TYPE prometheus_tsdb_wal_truncate_duration_seconds summary
prometheus_tsdb_wal_truncate_duration_seconds_sum 0.045582296
prometheus_tsdb_wal_truncate_duration_seconds_count 2
# HELP prometheus_tsdb_wal_truncations_failed_total Total number of write log truncations that failed.
# TYPE prometheus_tsdb_wal_truncations_failed_total counter
prometheus_tsdb_wal_truncations_failed_total 0
# HELP prometheus_tsdb_wal_truncations_total Total number of write log truncations attempted.
# TYPE prometheus_tsdb_wal_truncations_total counter
prometheus_tsdb_wal_truncations_total 2
# HELP prometheus_tsdb_wal_writes_failed_total Total number of write log writes that failed.
# TYPE prometheus_tsdb_wal_writes_failed_total counter
prometheus_tsdb_wal_writes_failed_total 0
# HELP prometheus_wal_watcher_current_segment Current segment the WAL watcher is reading records from.
# TYPE prometheus_wal_watcher_current_segment gauge
prometheus_wal_watcher_current_segment{consumer="10a14958-01f8-dd3c-d126-11111111111a"} 852
# HELP prometheus_wal_watcher_notifications_skipped_total The number of WAL write notifications that the Watcher has skipped due to already being in a WAL read routine.
# TYPE prometheus_wal_watcher_notifications_skipped_total counter
prometheus_wal_watcher_notifications_skipped_total{consumer="10a14958-01f8-dd3c-d126-11111111111a"} 2
# HELP prometheus_wal_watcher_record_decode_failures_total Number of records read by the WAL watcher that resulted in an error when decoding.
# TYPE prometheus_wal_watcher_record_decode_failures_total counter
prometheus_wal_watcher_record_decode_failures_total{consumer="10a14958-01f8-dd3c-d126-11111111111a"} 0
# HELP prometheus_wal_watcher_records_read_total Number of records read by the WAL watcher from the WAL.
# TYPE prometheus_wal_watcher_records_read_total counter
prometheus_wal_watcher_records_read_total{consumer="10a14958-01f8-dd3c-d126-11111111111a",type="samples"} 2621
prometheus_wal_watcher_records_read_total{consumer="10a14958-01f8-dd3c-d126-11111111111a",type="series"} 102
# HELP prometheus_wal_watcher_samples_sent_pre_tailing_total Number of sample records read by the WAL watcher and sent to remote write during replay of existing WAL.
# TYPE prometheus_wal_watcher_samples_sent_pre_tailing_total counter
prometheus_wal_watcher_samples_sent_pre_tailing_total{consumer="10a14958-01f8-dd3c-d126-11111111111a"} 0
# HELP prometheus_web_federation_errors_total Total number of errors that occurred while sending federation responses.
# TYPE prometheus_web_federation_errors_total counter
prometheus_web_federation_errors_total 0
# HELP prometheus_web_federation_warnings_total Total number of warnings that occurred while sending federation responses.
# TYPE prometheus_web_federation_warnings_total counter
prometheus_web_federation_warnings_total 0
# HELP promhttp_metric_handler_requests_in_flight Current number of scrapes being served.
# TYPE promhttp_metric_handler_requests_in_flight gauge
promhttp_metric_handler_requests_in_flight 1
# HELP promhttp_metric_handler_requests_total Total number of scrapes by HTTP status code.
# TYPE promhttp_metric_handler_requests_total counter
promhttp_metric_handler_requests_total{code="200"} 229
promhttp_metric_handler_requests_total{code="500"} 0
promhttp_metric_handler_requests_total{code="503"} 0